---
title: "Classification Trees"
author: "Niclas Frederic Sturm"
date: "3-11-2019"
output:
  html_document:
    theme: yeti
  pdf_document: default
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Dieses Dokument enthält die Programmierbefehle zur Erstellung von Modellen auf Basis von Entscheidungsbäumen. 

```{r message = FALSE}
library(readr)
library(dplyr)
library(rpart)
library(rpart.plot)
library(rsample)
library(Metrics)
library(ipred)
library(stringr)
library(purrr)
library(tibble)
library(gbm)
library(caret)
library(ranger)

set.seed(1997) # Set seed for reproducibility
setwd("/Users/nfsturm/Documents/STATLEARN/forestranger")

churn_data <- read_csv("employee_attrition.csv", col_names = TRUE)
drop_vars <- c("EmployeeCount", "EmployeeNumber", "Over18", "StandardHours", "HourlyRate", "MonthlyRate", "DailyRate")
churn_data <- churn_data %>%
  select(-drop_vars)

churn_data <- churn_data %>%
  mutate(Attrition = ifelse(Attrition == 'Yes', 1, 0))

factor_vars <- c("BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")

churn_data[factor_vars] <- lapply(churn_data[factor_vars], as.factor)

```

Auch für Klassifikationsaufgaben entspricht das *Split-Train-Test*-Paradigma gegenwärtigen Standards. 

```{r}
churn_splits <- initial_split(churn_data)
test <- testing(churn_splits)
train <- training(churn_splits)
actual <- test$Attrition
train2 <- train %>%
  mutate(Attrition = as.factor(Attrition)) 
# Das Caret-Package erfordert Faktorvariablen für Klassifikation
```

## Decision Trees

Die abhängige Variable - »Attrition« - wird nun zur Zielvariable eines einfachen Entscheidungsbaums. 

```{r}
tree_churn <- rpart(Attrition ~., data = train, method = "class")
```

Eine graphische Darstellung des Entscheidungsbaums zeigt, dass der Baum 13 verschiedene Kriterien zur Teilung verwendet. 

```{r}
rpart.plot(tree_churn, branch = 0.5, tweak = 1.5)
```

```{r}
predictions <- predict(tree_churn, test)
predictions <- ifelse(predictions > 0.5, 1, 0)
Metrics::accuracy(actual, predictions)
```

Der einzelne Baum erreicht eine Vorhersagegenauigkeit von 50%. 

```{r}
pruned_tree <- prune.rpart(tree_churn, cp = 0.025)
predictions <- predict(pruned_tree, test)
predictions <- ifelse(predictions > 0.5, 1, 0)
Metrics::accuracy(actual, predictions)
rpart.plot(pruned_tree, branch = 0.5)
```

Durch das »Zurückschneiden« lässt sich in der Regel das »Overfitting« nachträglich unterbinden. 

## Bagging 

```{r}
set.seed(1997)
nbagg_seq <- c(seq(1, 500, 25))

eval_df <- train %>%
  crossing(nbagg = nbagg_seq) %>%
  group_by(nbagg) %>%
  nest(.key = "train") %>%
  mutate(model = map2(train, nbagg, .f = ~bagging(formula = Attrition~., data = .x, nbagg = .y)))

test_nested <- nest(test)
test_nested <- test_nested %>%
  crossing(1:length(nbagg_seq)) %>%
  select(data)

colnames(test_nested) <- "test"

customRound <- function(x, threshold = 0.5) {
  rounded <- ifelse(x > threshold, 1, 0)
  return(rounded)
} 
"Um die Unsicherheit der Schätzung abzudecken, kann über diese Funktion
ein Grenzwert gewählt werden, ab dem eine binäre Schätzung vorgenommen wird."

bound_df <- bind_cols(eval_df, test_nested)
bound_df <- bound_df %>%
  mutate(test_actual = map(test, ~.x$Attrition)) %>%
  mutate(test_predicted = map2(model, test, ~predict(.x, .y))) %>%
  mutate(test_predicted = map(test_predicted, ~customRound(.x))) %>%
  mutate(test_accuracy = map2_dbl(test_actual, test_predicted, ~accuracy(actual = .x, predicted = .y)))

nbagg_tbl <- enframe(nbagg_seq, value = "nbagg", name = NULL)
accuracies_tbl <- enframe(bound_df$test_accuracy, value = "accuracy", name = NULL)
accuracies_df <- bind_cols(nbagg_tbl, accuracies_tbl)
```

Die Entwicklung des Genauigkeits-Maßs kann grafisch dargestellt werden. 

```{r}
ggplot(accuracies_df, aes(nbagg, accuracy)) + geom_point() + geom_line() + theme_classic() + 
  labs(title = "Genauigkeitsmaß nach Anzahl der Bootstrap-Replikationen", caption = "Verwendung 20 diskreter Werte") + 
  xlab("Anzahl der aggregierten Bäume") + ylab("Genauigkeit") + scale_y_continuous(limits = c(0.8, 0.87)) + scale_x_continuous(limits = c(0, 500))
```

Für einen Aggregationswert von 26 hat das Modell die höchste Genauigkeit für den Test-Datensatz mit 85.3%. 

## Boosting

```{r}
set.seed(1997)
boost_model <- gbm(Attrition~., distribution = "multinomial", data = train, n.trees = 500, shrinkage = 0.002, n.minobsinnode = 10, cv.folds = 10)
predicted <- predict.gbm(boost_model, newdata = test, n.trees = 500, type = "response") 
predicted <- predicted[,-1,1]
predicted <- ifelse(predicted > 0.5, 1,0)
accuracy <- Metrics::accuracy(actual, predicted)
accuracy
```

Die Vorhersagegenauigkeit des besten Modells für eine Lernrate von 0.002 beträgt etwa 83%. Es kann aber auch eine Rastersuche vorgenommen werden, um größeren Einfluss auf das Modell zu erhalten.

```{r}
set.seed(1997) # ¡Sehr lange Laufzeit der nächsten Zeilen!
boost_grid <- expand.grid(n.trees = c(100, 200, 300, 500, 700, 900),
 interaction.depth = 5,
 shrinkage = c(0.0125, 0.025, 0.05, 0,075, 0.1),
 n.minobsinnode = 5)

boost_model <- train(Attrition ~ ., data = train2, method = "gbm", distribution = "adaboost",tuneGrid = boost_grid, verbose = FALSE)
```




## Random Forest

```{r}
set.seed(1997)

grid <- expand.grid(mtry = seq(1,100, 2))
control <- trainControl(method="cv", number = 10)
ranger_model <- train(Attrition ~., data = train2, method = "ranger", importance = "impurity")
var_imp <- varImp(ranger_model, scale = FALSE)$importance
var_imp <- rownames_to_column(var_imp, "Variable")
var_imp$Variable <- factor(var_imp$Variable, levels = var_imp$Variable[order(var_imp$Overall)])
var_imp <- var_imp %>%
  filter(Overall > 8)
```

```{r}
ggplot(var_imp, aes(Variable, Overall, fill = Overall)) + geom_col(aes(fill = Overall)) + coord_flip() + theme_classic() + labs(title = "Variableneinfluss im Random Forest", subtitle = "Anmerkung: Cut-Off bei 8%") + geom_text(aes(label=round(Overall, digits = 2)), nudge_y =1, col = "black") + scale_fill_gradient2(low="#e7eff6", high="#63ace5")
```

Die Entwicklung der Vorhersagegenauigkeit kann auch bei Klassifikationsaufgaben anhand des Parameters »Mtry« visualisiert werden. 

```{r}
set.seed(1997)
grid <- expand.grid(mtry = seq(1,26, 1), min.node.size = 1, splitrule = "gini")
control <- trainControl(method="cv", number = 10)
ranger_model <- train(Attrition ~., data = train2, method = "ranger", importance = "impurity", tuneGrid = grid, trControl = control)

ggplot(ranger_model) + geom_point(col = "#7fa9c1", size = 3) + geom_line(col = "#7fa9c1", size = 1) + theme_classic() + xlab("Anzahl von Mtry") + scale_x_continuous(breaks = seq(1, 26, 2)) + scale_y_continuous(limits = c(0.84, 0.87)) + labs(title = "Random Forest Accuracy", subtitle = "Optimierung durch Kreuzvalidierung") 

```

Die beste Performance ergibt sich für mtry = 24. 

```{r}
set.seed(1997)
ranger_model_best <- ranger(Attrition~., data = train, mtry = 19)
ranger_preds <- predict(ranger_model_best, test)
predictions <- customRound(ranger_preds$predictions)
Metrics::accuracy(actual, predictions)
```

Es ergibt sich eine Genauigkeit von ca. 84.5%. 